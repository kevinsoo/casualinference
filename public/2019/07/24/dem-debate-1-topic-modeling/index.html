<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.54.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Dem Debate 1: Topic modeling &middot; Casual Inference</title>

  
  <link type="text/css" rel="stylesheet" href="/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="/css/poole.css">
  <link type="text/css" rel="stylesheet" href="/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">

  
  <link rel="icons8-scatter-plot-90" sizes="144x144" href="/icons8-scatter-plot-90.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Casual Inference" />

  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="/"><h1>Casual Inference</h1></a>
      <p class="lead">
      Adventures of a Data Scientist <a href="http://twitter.com/civisanalytics">@CivisAnalytics</a><br>Occasional causal inferences
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        
        <li><a href="/about/"> About </a></li><li><a href="/post/"> Posts </a></li><li><a href="/categories/"> Categories </a></li><li><a href="/tags/"> Tags </a></li>
      </ul>
    </nav>
    
    <div>
        <h3 class="white">Links</h3>
        <i class="fab fa-twitter fa-fw"></i> <a href="http://twitter.com/kevinwxsoo">Twitter</a><br>
        <i class="fab fa-github fa-fw"></i> <a href="https://github.com/kevinsoo">GitHub</a><br>
        <i class="far fa-envelope fa-fw"></i> <a href="mailto:kevinwxsoo@gmail.com?Subject=Hello">Email</a><br>
        <br>
    </div>

    <p>&copy; 2019. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Dem Debate 1: Topic modeling</h1>
  <time datetime=2019-07-24T00:00:00Z class="post-date">Wed, Jul 24, 2019</time>
  


<p>The second Democratic debate is almost here, so I wanted to follow up the <a href="https://casualinference.netlify.com/2019/07/02/dem-debate-1-sentiment-analysis/">sentiment analysis</a> I performed on the first debate by looking at the topics that were talked about across the two nights.</p>
<p>In <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, a <a href="http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/">topic model</a> is a statistical model that can be used to infer the underlying meanings (i.e. <em>topics</em>) of utterances based on the words being used. In this post, I use <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> (LDA) from the <code>topicmodels</code> package to infer what each speech by the candidates is about. The model assumes:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Every speech is about a mixture of topics.</strong> For example, in a reply to a question by a moderator, a candidate might be speaking about the economy, or about the economy <em>and</em> climate change, etc. In contrast to other classification methods that try to identify only a single underlying category, LDA assigns probabilities to each topic, indicating the probability that a speech is about that topic.</p></li>
<li><p><strong>Each topic of interest is spoken about using a reliable collection of words.</strong> For example, when speaking about a topic like healthcare, a candidate may use words like “insurance” and “medicare”. If we assume that an underlying topic generates certain words, each topic can be described as a collection of frequently co-occurring words.</p></li>
</ol>
<div id="identifying-topics" class="section level2">
<h2>Identifying topics</h2>
<p>Determining the number of topics (<em>k</em>) that are talked about within a corpus (i.e. all speeches during the two nights of the first Democratic debate) is a tricky endeavour. There are various approaches to determining the optimal <em>k</em> (e.g., <a href="http://doi.org/10.1073/pnas.0307752101">Griffiths &amp; Steyvers, 2004</a>; <a href="https://link.springer.com/chapter/10.1007%2F978-3-642-13657-3_43">Arun et al., 2010</a>), but these methods do not always converge. A more practical issue is that the optimal <em>k</em> computed via such methods may not be semantically meaningful.</p>
<p>For this post, I went with <em>k</em> = 4, because it led to semantically interpretable topics.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The following figure displays the four topics the model identified in the transcripts of the first Democratic debate. Within each topic, the figure plots the beta weights of the top eight terms.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Beta represents the probability of a term being generated by that topic. I believe the terms in each topic make the labels pretty self-explanatory.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/topics-1.png" width="672" /></p>
<p>While the four topics – <em>Economy</em>, <em>Future generations</em>, <em>Healthcare</em>, and <em>International affairs</em> – are certainly not exhaustive, I believe they can be useful as broad categories for looking at patterns in what the debates were about.</p>
</div>
<div id="topics-over-time" class="section level2">
<h2>Topics over time</h2>
<p>After identifying the topics of interest, we can look at the inferences the model makes about each speech. For example, when Pete Buttigieg speaks at a particular juncture, what topic does the model infer as being the most probable? In the following figures, I display each topic’s gamma values for every speech (separately for the first and second nights of the debate). Gamma represents the probability of a speech being about a particular topic (gammas for all four topics sum to 1).</p>
<p>The speeches are arranged chronologically, painting a picture of how the topics being discussed changed over the course of each debate. In the first row, I have visualized the gamma values for each speech using bars, to illustrate the most salient topics at each point in time (note the changes in color). In the second row, I visualized the gamma values using points, and included trend lines to show how the the salience of each topic changed over time.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/topicsTime-1.png" width="1152" /></p>
<p>From these plots, it’s clear that on both nights, candidates started by talking about the economy (and to a lesser extent, healthcare). Around the quarter-mark, candidates started talking about issues faced by future generations (gun control, climate change, etc.). There were also differences; on the first night, candidates shifted to talking about international affairs towards the end of the debate, while on the second night this occured around the midpoint.</p>
</div>
<div id="topics-by-candidate" class="section level2">
<h2>Topics by candidate</h2>
<p>Finally, I wanted to see if candidates differed in the topics they tended to focus on in their speeches. To do this, I computed the average gamma within each topic for each candidate (higher average gammas indicate a candidate’s speeches were more likely to be about a particular topic). This results in candidate profiles of the relative importance of each topic.</p>
<p>Before displaying these profiles, I wanted to categorize candidates based on their similarity to aid interpretation. To do this, I used <a href="https://uc-r.github.io/hc_clustering">hierarchical clustering</a> (from the <code>cluster</code> package) to identify groups of candidates based on the pattern of their average gamma for the various topics. This clustering method identifies these groups based on the similarities between candidates, which I visualized in the following dendrogram. Based on the relative importance of each topic in their speeches, there are four groups of candidates.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/dendro-1.png" width="672" /></p>
<div id="economy-plus-candidate" class="section level4">
<h4>Economy-plus candidate</h4>
<p>First comes Andrew Yang in a class of his own. He only made seven speeches, but focused very heavily on the economy relative to other topics.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/groupA-1.png" width="288" /></p>
</div>
<div id="healthcare-now-candidates" class="section level4">
<h4>Healthcare-now candidates</h4>
<p>The following four candidates have topic distributions that favor healthcare over talking about issues facing future generations.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/groupC-1.png" width="576" /></p>
</div>
<div id="worldly-candidates" class="section level4">
<h4>Worldly candidates</h4>
<p>These six candidates seemed to focus just a bit more on international affairs than other topics.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/groupD-1.png" width="864" /></p>
</div>
<div id="scattered-candidates" class="section level4">
<h4>Scattered candidates</h4>
<p>It’s hard to succintly describe the patterns of the remaining nine candidates. I couldn’t help notice that Cory Booker’s topic distribution is eerily similar to Marianne Williamson. He might want to do more to differentiate himself a little in his speech from <a href="https://gizmodo.com/marianne-williamson-loves-spreading-fake-quotes-from-al-1836630042">Marianne</a>.</p>
<p><img src="/post/2019-07-24-dem-debate-1-topic-modeling_files/figure-html/groupB-1.png" width="864" /></p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Natural language processing is complex. While using a model to infer topics from speech helps in understanding broad patterns and trends, no list of topics will fully capture the topics that were actually being spoken about. While the LDA model used here assumes that each topic is identifiable based on particular terms, different candidates may use terms in different ways.</p>
<p>Furthermore, when considering the topics different candidates tend to focus on, it’s worth noting that the topics they address are influenced by moderators and the speeches of other candidates that came before. While the plots above reveal the topics each candidate focused on during the last debate, this does not necessarily correspond to the importance the candidate places on that topic.</p>
<p>Despite these limitations, I believe that such analyses are useful for gaining a general picture of the topics candidates were focusing on in their speeches.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://eyarzebinski.com">Evelyn Yarzebinski</a> found this approach lacking, so I used the <code>ldatuning</code> package to <a href="https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html">evaluate the optimal <em>k</em></a>. However, this led to an optimal <em>k</em> of 9 or 10, resulting in topics with terms that were hard to meaningfully discern. I didn’t want to sacrifice interpretability, hence my decision to stick with <em>k</em> = 4.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>I excluded stopwords (“the”, “and”, “a”…) and non-diagnostic words that were associated with multiple topics (“president”, “america”, “country”, “people”, and “united states”).<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>

</div>


    </main>

    
  </body>
</html>
